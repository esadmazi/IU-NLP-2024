{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Data loading with pandas\n",
    "def load_data(filename):\n",
    "    return pd.read_json(filename, lines=True)\n",
    "\n",
    "train_data = load_data('train.jsonl')\n",
    "dev_data = load_data('test1.jsonl')\n",
    "dev_data = dev_data.rename(columns= {'senences': 'sentences'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Владелец «Бирмингема» получил шесть лет тюрьмы...</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Акция протеста на Майдане Независимости объявл...</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фольксваген может перейти под контроль Порше \\...</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>В Москве покажут фильмы Чарли Чаплина с живой ...</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Чулпан Хаматова сыграет главную роль в фильме ...</td>\n",
       "      <td>588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ОБСЕ назвала референдум о статусе Крыма незако...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Египетского студента могут выслать из страны з...</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Геннадий Онищенко отправлен в отставку\\nГеннад...</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Племянник Алишера Усманова разбился в ДТП\\nВид...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Владимир Булавин назначен на новую должность —...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentences   id\n",
       "0   Владелец «Бирмингема» получил шесть лет тюрьмы...  584\n",
       "1   Акция протеста на Майдане Независимости объявл...  585\n",
       "2   Фольксваген может перейти под контроль Порше \\...  586\n",
       "3   В Москве покажут фильмы Чарли Чаплина с живой ...  587\n",
       "4   Чулпан Хаматова сыграет главную роль в фильме ...  588\n",
       "..                                                ...  ...\n",
       "60  ОБСЕ назвала референдум о статусе Крыма незако...  644\n",
       "61  Египетского студента могут выслать из страны з...  645\n",
       "62  Геннадий Онищенко отправлен в отставку\\nГеннад...  646\n",
       "63  Племянник Алишера Усманова разбился в ДТП\\nВид...  647\n",
       "64  Владимир Булавин назначен на новую должность —...  648\n",
       "\n",
       "[65 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dict(data):\n",
    "    label_set = set()\n",
    "    for annotations in data['ners']:\n",
    "        for _, _, label in annotations:\n",
    "            label_set.add(label)\n",
    "    return {label: idx for idx, label in enumerate(label_set)}\n",
    "\n",
    "label_dict = get_label_dict(train_data)\n",
    "label_dict['O'] = 29\n",
    "inverse_label_dict = {v: k for k, v in label_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_name, num_labels):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    model = BertForTokenClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_labels,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    )\n",
    "    return tokenizer, model\n",
    "\n",
    "tokenizer, model = load_model('bert-base-multilingual-cased', len(label_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, tokenizer, label_dict=None, max_len=128, include_labels=True):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        sentence = row['sentences']\n",
    "        tokenized_info = tokenizer(sentence, max_length=max_len, padding='max_length', truncation=True)\n",
    "        input_ids.append(tokenized_info['input_ids'])\n",
    "        attention_masks.append(tokenized_info['attention_mask'])\n",
    "        \n",
    "        if include_labels and 'ners' in row:\n",
    "            label_array = [label_dict['O']] * max_len  # Initialize with 'O' for non-entity\n",
    "            for start, end, label in row['ners']:\n",
    "                for i in range(start, min(end, max_len)):\n",
    "                    label_array[i] = label_dict[label]\n",
    "            labels.append(label_array)\n",
    "    \n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "    if include_labels:\n",
    "        labels = torch.tensor(labels)\n",
    "        return TensorDataset(input_ids, attention_masks, labels)\n",
    "    return TensorDataset(input_ids, attention_masks)\n",
    "\n",
    "train_dataset = prepare_data(train_data, tokenizer, label_dict)\n",
    "dev_dataset = prepare_data(dev_data, tokenizer, include_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/esadmazi/miniforge3/envs/mlp/lib/python3.11/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Training:   0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [02:29<00:00,  8.82s/it]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.classifier.parameters(), lr=5e-5)\n",
    "\n",
    "def train_and_evaluate(model, train_dataloader, dev_dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    for epoch in range(1):  # Number of epochs\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs, masks, labels = batch\n",
    "            model.zero_grad()\n",
    "            outputs = model(inputs, token_type_ids=None, attention_mask=masks, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "train_and_evaluate(model, train_dataloader, dev_dataloader, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FACILITY': 0,\n",
       " 'LANGUAGE': 1,\n",
       " 'PERCENT': 2,\n",
       " 'PERSON': 3,\n",
       " 'FAMILY': 4,\n",
       " 'DISTRICT': 5,\n",
       " 'LOCATION': 6,\n",
       " 'EVENT': 7,\n",
       " 'PROFESSION': 8,\n",
       " 'MONEY': 9,\n",
       " 'ORDINAL': 10,\n",
       " 'IDEOLOGY': 11,\n",
       " 'CRIME': 12,\n",
       " 'STATE_OR_PROVINCE': 13,\n",
       " 'WORK_OF_ART': 14,\n",
       " 'AGE': 15,\n",
       " 'AWARD': 16,\n",
       " 'DATE': 17,\n",
       " 'PENALTY': 18,\n",
       " 'NATIONALITY': 19,\n",
       " 'NUMBER': 20,\n",
       " 'TIME': 21,\n",
       " 'DISEASE': 22,\n",
       " 'LAW': 23,\n",
       " 'RELIGION': 24,\n",
       " 'PRODUCT': 25,\n",
       " 'ORGANIZATION': 26,\n",
       " 'COUNTRY': 27,\n",
       " 'CITY': 28,\n",
       " 'O': 29}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 3/3 [00:05<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "def generate_predictions(model, dataloader, data_ids):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for i, batch in enumerate(tqdm(dataloader, desc=\"Predicting\")):\n",
    "        inputs, masks = batch[0].to(device), batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs, token_type_ids=None, attention_mask=masks).logits\n",
    "        preds = torch.argmax(logits, dim=2)\n",
    "        batch_predictions = preds.cpu().numpy().tolist()\n",
    "        \n",
    "        # Iterate over batch predictions and associate each with its corresponding data ID\n",
    "        for j, pred in enumerate(batch_predictions):\n",
    "            ners = [[0, 0, inverse_label_dict[p]] for p in pred if p != label_dict[\"O\"]]\n",
    "            predictions.append({\"id\": data_ids[i * len(batch) + j], \"ners\": ners})\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Get ids from dev_data to pass to the prediction function\n",
    "dev_ids = dev_data['id'].tolist()\n",
    "predictions = generate_predictions(model, dev_dataloader, dev_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19354.97s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "updating: test.jsonl (deflated 94%)\n"
     ]
    }
   ],
   "source": [
    "with open('test.jsonl', 'w') as file:\n",
    "    for prediction in predictions:\n",
    "        file.write(json.dumps(prediction) + \"\\n\")\n",
    "\n",
    "# Zip the file for submission\n",
    "!zip test.zip test.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
